{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\logging\\__init__.py\", line 978, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\logging\\__init__.py\", line 828, in format\n",
      "    return fmt.format(record)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\logging\\__init__.py\", line 573, in format\n",
      "    record.exc_text = self.formatException(record.exc_info)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\logging\\__init__.py\", line 523, in formatException\n",
      "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\traceback.py\", line 169, in print_exception\n",
      "    for line in _format_exception_iter(etype, value, tb, limit, chain):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\traceback.py\", line 146, in _format_exception_iter\n",
      "    for value, tb in values:\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\traceback.py\", line 125, in _iter_chain\n",
      "    context = exc.__context__\n",
      "AttributeError: 'NoneType' object has no attribute '__context__'\n",
      "Call stack:\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\runpy.py\", line 170, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\traitlets\\config\\application.py\", line 589, in launch_instance\n",
      "    app.start()\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 405, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\tornado\\ioloop.py\", line 883, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 260, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 212, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 175, in do_execute\n",
      "    shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2723, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2825, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-239b803240dd>\", line 6, in <module>\n",
      "    import theano.tensor as T\n",
      "  File \"<frozen importlib._bootstrap>\", line 2237, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 2212, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 321, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 2237, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 2226, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1200, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1129, in _exec\n",
      "  File \"<frozen importlib._bootstrap>\", line 1471, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 321, in _call_with_frames_removed\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\theano\\__init__.py\", line 156, in <module>\n",
      "    import theano.gpuarray\n",
      "  File \"<frozen importlib._bootstrap>\", line 2237, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 2226, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1200, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1129, in _exec\n",
      "  File \"<frozen importlib._bootstrap>\", line 1471, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 321, in _call_with_frames_removed\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 252, in <module>\n",
      "    exc_info=True)\n",
      "Message: 'pygpu was configured but could not be imported or is too old (version 0.7 or higher required)'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import lasagne\n",
    "import lasagne.nonlinearities as nonlin\n",
    "import pylab\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import imageio\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import PIL\n",
    "\n",
    "from net.vgg16 import make_network_from_file\n",
    "from net.process import preprocess, resize_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataDir='annotations_trainval2017'\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/captions_{}.json'.format(dataDir, dataType)\n",
    "\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_from_anns(anns):\n",
    "    return [(str(v[1]['image_id']), v[1]['caption']) for v in anns.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# img2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from net.imgs import *\n",
    "      \n",
    "# %time imgs_process('annotations_trainval2017/img') # Wall time: 4h 43min 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4991"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = imgs_load(dataDir)\n",
    "display(len(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "ERROR: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-531d091b2409>\", line 3, in <module>\n",
      "    w2v = load_w2v(5*10**5)\n",
      "  File \"E:\\HSE_deeplearning\\net\\word2vec.py\", line 37, in load_w2v\n",
      "    'net/GoogleNews-vectors-negative300.bin', binary=True, limit=limit)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\gensim\\models\\keyedvectors.py\", line 242, in load_word2vec_format\n",
      "    weights = fromstring(fin.read(binary_len), dtype=REAL)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1827, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 300, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n"
     ]
    }
   ],
   "source": [
    "from net.word2vec import *\n",
    "\n",
    "w2v = load_w2v(5*10**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-7b69c2614809>\", line 2, in <module>\n",
      "    from net.x_process import *\n",
      "ImportError: No module named 'net.x_process'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1827, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 300, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\inspect.py\", line 1338, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\inspect.py\", line 1298, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\inspect.py\", line 583, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\inspect.py\", line 626, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\inspect.py\", line 595, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\inspect.py\", line 580, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'net.x_process'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from net.sents_process import *\n",
    "from net.x_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "danno = sents_load(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "captions = [text[1]['caption'] for text in coco.anns.items()]\n",
    "display(captions[:5])\n",
    "\n",
    "plt.hist(list(map(lambda x: len(x.split(' ')), captions)),bins=100)\n",
    "t = np.argmax(list(map(lambda x: len(x.split(' ')), captions)))\n",
    "display(captions[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from net.train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = 300\n",
    "W = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 23300\n",
    "\n",
    "    \n",
    "    \n",
    "X, y = [], []\n",
    "for id, data in imgs.items():\n",
    "    while id[0] == '0':\n",
    "        id = id[1:]\n",
    "    try:\n",
    "        for ls in danno[id]:\n",
    "            vects = []\n",
    "            for elem in ls:\n",
    "                if not isinstance(elem, str):\n",
    "                    vects.append(elem)\n",
    "            vects = procces_x(vects)\n",
    "            X.append(vects)\n",
    "            y.append(data[1])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "X_train, y_train, X_val, y_val = X[:train_size], y[:train_size], X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(file_name=None):\n",
    "    net = NeuralNet(must_have=[\n",
    "            'input_shape', \n",
    "            'learning_rate', \n",
    "            'train_fun', \n",
    "            'loss_fun', \n",
    "            'loss_fun_det', \n",
    "            'predict_fun_det'])\n",
    "    \n",
    "    input_shape = [None, H, W]\n",
    "    \n",
    "    input_X = T.tensor3(\"input X\", dtype='float32')\n",
    "    target_y = T.matrix(\"target Y\", dtype='float32')\n",
    "\n",
    "    \n",
    "    net['inp'] = lasagne.layers.InputLayer(input_shape, input_var=input_X)\n",
    "    \n",
    "    net['max'] = lasagne.layers.GlobalPoolLayer(net['inp'], pool_function=theano.tensor.max)\n",
    "    net['min'] = lasagne.layers.GlobalPoolLayer(net['inp'], pool_function=theano.tensor.min)\n",
    "    net['mean'] = lasagne.layers.GlobalPoolLayer(net['inp'], pool_function=theano.tensor.mean)\n",
    "    \n",
    "    net['con_2'] = lasagne.layers.Conv1DLayer(net['inp'], num_filters=64, filter_size=2,nonlinearity=None)\n",
    "    net['con_3'] = lasagne.layers.Conv1DLayer(net['inp'], num_filters=64, filter_size=3,nonlinearity=None)\n",
    "    net['con_4'] = lasagne.layers.Conv1DLayer(net['inp'], num_filters=64, filter_size=4,nonlinearity=None)\n",
    "    \n",
    "    net['gmax_2'] = lasagne.layers.GlobalPoolLayer(net['con_2'], pool_function=T.max)\n",
    "    net['gmax_3'] = lasagne.layers.GlobalPoolLayer(net['con_3'], pool_function=T.max)\n",
    "    net['gmax_4'] = lasagne.layers.GlobalPoolLayer(net['con_4'], pool_function=T.max)\n",
    "    \n",
    "    net['merge'] = lasagne.layers.ConcatLayer((net['max'], net['min'], net['mean'], \n",
    "                                               net['gmax_2'], net['gmax_3'], net['gmax_4']))\n",
    "    \n",
    "    net['dens_1'] = lasagne.layers.DenseLayer(net['merge'], num_units=500, nonlinearity=nonlin.elu)\n",
    "    net['batch_1'] =  lasagne.layers.batch_norm(net['dens_1'])\n",
    "    net['drop_1'] = lasagne.layers.DropoutLayer(net['batch_1'], p=0.5)\n",
    "    \n",
    "    net['dens_2'] = lasagne.layers.DenseLayer(net['drop_1'], num_units=500, nonlinearity=nonlin.elu)\n",
    "    net['batch_2'] =  lasagne.layers.batch_norm(net['dens_2'])\n",
    "    net['drop_2'] = lasagne.layers.DropoutLayer(net['batch_2'], p=0.5)\n",
    "    \n",
    "    net['last'] = lasagne.layers.DenseLayer(net['drop_2'], num_units=4096)\n",
    "    \n",
    "    \n",
    "    y_predicted = lasagne.layers.get_output(net['last'])\n",
    "    y_predicted_det = lasagne.layers.get_output(net['last'], deterministic=True)\n",
    "\n",
    "    all_weights = lasagne.layers.get_all_params(net['last'], trainable=True)\n",
    "    \n",
    "    learning_rate = theano.shared(lasagne.utils.floatX(0.001))\n",
    "    loss = lasagne.objectives.squared_error(target_y, y_predicted).mean()\n",
    "    loss_det = lasagne.objectives.squared_error(target_y, y_predicted_det).mean()\n",
    "    \n",
    "    # loss = loss + lasagne.regularization.regularize_layer_params(net['last'], lasagne.regularization.l2) * 0.01\n",
    "    updates = lasagne.updates.adam(loss, all_weights, learning_rate=learning_rate)\n",
    "    \n",
    "    train_fun = theano.function([input_X, target_y], loss, updates=updates, allow_input_downcast=True)\n",
    "    loss_fun = theano.function([input_X, target_y], loss, allow_input_downcast=True)\n",
    "    loss_fun_det = theano.function([input_X, target_y], loss_det, allow_input_downcast=True)\n",
    "    predict_fun_det = theano.function([input_X], y_predicted_det, allow_input_downcast=True)\n",
    "    \n",
    "    if file_name:\n",
    "        load_net(net['last'], file_name, dataDir)\n",
    "    \n",
    "    net.input_shape = input_shape\n",
    "    net.learning_rate = learning_rate\n",
    "    net.train_fun = train_fun\n",
    "    net.loss_fun = loss_fun\n",
    "    net.loss_fun_det = loss_fun_det\n",
    "    net.predict_fun_det = predict_fun_det\n",
    "    \n",
    "    return net.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = build_cnn('new_cnn2.3v_2.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    words = sent2words(text)\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            vecs.append(w2v[word])\n",
    "        except:\n",
    "            pass\n",
    "    return procces_x(vecs)\n",
    "\n",
    "text2vec('dog run').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    img = img.resize((200,200), PIL.Image.ANTIALIAS)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def show_img_by_id(img_id, dataDir=dataDir):\n",
    "    show_img(imageio.imread(dataDir + '/img/' + img_id + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_imgs_by_vec(vec, imgs=imgs):\n",
    "    return [(id, np.linalg.norm(vec - point[1])) for id, point in imgs.items()]\n",
    "\n",
    "def show_t2i(text, count=3, net=net):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    good_imgs = get_imgs_by_vec(vec)\n",
    "    good_imgs.sort(key=lambda x: x[1])\n",
    "    good_imgs = good_imgs[:count]\n",
    "    display(good_imgs)\n",
    "    for id, _ in good_imgs:\n",
    "        print(id)\n",
    "        show_img_by_id(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('baby with mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_cap(mod=100):\n",
    "    result = []\n",
    "    for i, text in enumerate(captions)\n",
    "        result.append(net.predict_fun_det([text2vec(text)])[0])\n",
    "        if i % mod == 0:\n",
    "            print('Processed {}'.format(i))\n",
    "    return result\n",
    "\n",
    "procesed_captions = process_cap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_texts_by_vec(vec, texts=captions, procesed_texts=procesed_captions):\n",
    "    result = []\n",
    "    for text, point in zip(texts, procesed_texts):\n",
    "        dis = np.linalg.norm(vec - point)\n",
    "        result.append((text, dis))\n",
    "    result.sort(key=lambda x: x[1])\n",
    "    return result\n",
    "\n",
    "def show_i2t(img_id, count=3, imgs=imgs):\n",
    "    show_img_by_id(img_id)\n",
    "    vec = imgs[img_id][1]\n",
    "    good_text = get_texts_by_vec(vec)[:count]\n",
    "    print(*good_text, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_i2t('000000565597', count=5)\n",
    "show_i2t('000000564280', count=5)\n",
    "show_i2t('000000554291', count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_texts_by_text(text, net=net, texts=captions, procesed_texts=procesed_captions):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    result = []\n",
    "    for text, point in zip(texts, procesed_texts):\n",
    "        dis = np.linalg.norm(vec - point)\n",
    "        result.append((text, dis))\n",
    "    result.sort(key=lambda x: x[1])\n",
    "    return result\n",
    "\n",
    "def show_t2t(text, count=3):\n",
    "    print(text)\n",
    "    good_text = get_texts_by_text(text)[:count]\n",
    "    print(*good_text, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_t2t('A big dog is running')\n",
    "show_t2t('Green apple')\n",
    "show_t2t('donut on the table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import process\n",
    "\n",
    "def frames_load(dir_name):\n",
    "    frames = {}\n",
    "    for file_name in os.listdir(dir_name + '/video_data'):\n",
    "        if '.' in file_name and file_name.split('.')[1] == 'data':\n",
    "            with open('{}/video_data/{}'.format(dir_name, file_name), 'rb') as fl:\n",
    "                data = pickle.load(fl)\n",
    "                frames.update(data)\n",
    "    return frames\n",
    "\n",
    "frames = frames_load(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_v = {k: v['fc7'] for k, v in frames.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_name = 'Africa.mp4'\n",
    "vd = imageio.get_reader(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.interpolate as interpolate\n",
    "from pandas import ewma\n",
    "\n",
    "def show_video_t2i(text, count=3, net=net):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    good_frames = get_imgs_by_vec(vec, imgs=imgs_v)\n",
    "    good_frames.sort(key=lambda x: x[1])\n",
    "    good_frames = good_frames[:count]\n",
    "    display(good_frames)\n",
    "    for id, _ in good_frames:\n",
    "        print(id)\n",
    "        show_img(vd.get_data(id))\n",
    "        \n",
    "def show_video_t2graph(text, net=net):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    good_frames = get_imgs_by_vec(vec, imgs=imgs_v)\n",
    "    good_frames.sort(key=lambda x: x[1])\n",
    "    \n",
    "    mx = good_frames[50][1]\n",
    "    good_frames.sort(key=lambda x: x[0])\n",
    "    \n",
    "    x, y = np.transpose(good_frames)\n",
    "    \n",
    "    pic = np.array(list(map(lambda t: 1.0 if t < mx else 0.0, y)))\n",
    "    wind = 20\n",
    "    res = []\n",
    "    res_x = []\n",
    "    for i in range(len(pic) - wind):\n",
    "        s = 0\n",
    "        for j in range(wind):\n",
    "            s += pic[i + j]\n",
    "        res.append(s)\n",
    "        res_x.append(x[i] / 25 / 60)\n",
    "    \n",
    "    plt.plot(res_x, res)\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "    x, y = np.transpose(good_frames)\n",
    "    y = ewma(y, span=3)\n",
    "    y = y - np.min(y)\n",
    "    y = np.log(y)\n",
    "    y = ewma(y, span=2)\n",
    "    plt.plot(y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_video_t2graph('a couple of people that are playing in a field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_video_t2i('tiger tiger tiger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_from_time(time, id='8kBGjNI2bwA'):\n",
    "    return \"https://youtu.be/{}?t={}\".format(id, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_i2t(10, imgs=imgs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
