{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-239b803240dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import lasagne\n",
    "import lasagne.nonlinearities as nonlin\n",
    "import pylab\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import imageio\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import PIL\n",
    "\n",
    "from net.vgg16 import make_network_from_file\n",
    "from net.process import preprocess, resize_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataDir='annotations_trainval2017'\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/captions_{}.json'.format(dataDir, dataType)\n",
    "\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(541200,\n",
       "  {'caption': 'a glass vase with some flower coming out of it ',\n",
       "   'id': 541200,\n",
       "   'image_id': 159282}),\n",
       " (262135,\n",
       "  {'caption': 'A tennis player is taking a swing on a red court.',\n",
       "   'id': 262135,\n",
       "   'image_id': 551804}),\n",
       " (589821,\n",
       "  {'caption': 'there is a yellow notebook on a black desk ',\n",
       "   'id': 589821,\n",
       "   'image_id': 176446})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(coco.anns))\n",
    "display(list(coco.anns.items())[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and load VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net, prob_and_vec = make_network_from_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# img2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from net.imgs import *\n",
    "      \n",
    "# %time imgs_process('annotations_trainval2017/img') # Wall time: 4h 43min 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4991"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = imgs_load(dataDir)\n",
    "display(len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = 11.9422037352\n",
      "min = 0.0\n"
     ]
    }
   ],
   "source": [
    "temp = pickle.load(open('annotations_trainval2017\\data\\\\130.data', 'rb'))\n",
    "temp = list(temp.items())\n",
    "print('max =', np.max(temp[10][1][1]))\n",
    "print('min =', np.min(temp[10][1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from net.word2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4c0315d539a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStemmingHelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'learning'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStemmingHelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal_form\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'learn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "print(StemmingHelper.stem('learning'))\n",
    "print(StemmingHelper.original_form('learn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7664012231 \n",
      "\n",
      "['refurbished', 'criminal', 'vivo', 'integrating', 'illiteracy', 'Exporters', 'mirrors', 'Zoom', 'John_Boehner', 'Eastwood'] \n",
      "\n",
      "[('dog', 0.7678031921386719), ('dogs', 0.6555119752883911), ('puppy', 0.6472997069358826), ('pit_bull', 0.6181665658950806), ('Dog', 0.6132033467292786), ('pooch', 0.6008472442626953), ('cat', 0.5838526487350464), ('pup', 0.5834978818893433), ('canines', 0.5686283111572266), ('pet', 0.5643360614776611)] \n",
      "\n",
      "[('teaching', 0.791033148765564), ('teach', 0.7432790994644165), ('learning', 0.7312349081039429), ('taught', 0.6442131400108337), ('Teaching', 0.6000475883483887), ('curriculum', 0.5869861841201782), ('teaches', 0.5792646408081055), ('instruction', 0.5679458975791931), ('classroom', 0.5501187443733215), ('instructional', 0.5340907573699951)]\n"
     ]
    }
   ],
   "source": [
    "w2v = load_w2v(5*10**4)\n",
    "\n",
    "print(w2v.similarity('woman', 'man'), '\\n')\n",
    "print(list(w2v.vocab)[:10], '\\n')\n",
    "print(w2v.most_similar(positive=[w2v['Learning'] - w2v['learning'] + w2v['dog']]), '\\n')\n",
    "print(w2v.most_similar(positive=[w2v['learning'] - w2v['learn'] + w2v['teach']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from net.sents_process import *\n",
    "\n",
    "# sents_process(dict_from_anns(coco.anns), 'annotations_trainval2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anno = sents_load(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "danno = anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two mean are playing tennis and both are wearing sunglasses.  ',\n",
       " 'a couple of people that are playing in a field',\n",
       " 'A purple and white bus in a parking lot.',\n",
       " 'a tennis player swinging a racket at a ball',\n",
       " 'a person attempting a jump with a skateboard']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "captions = [text[1]['caption'] for text in coco.anns.items()]\n",
    "display(captions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-668a7a732084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdanno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mvects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmix_text_vec2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-668a7a732084>\u001b[0m in \u001b[0;36mmix_text_vec2vec\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmix_text_vec2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0monly_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmatr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monly_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     return np.concatenate((\n\u001b[0;32m      5\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \"\"\"\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "from notebook.dense.helper import mix_text_vec2vec\n",
    "\n",
    "vects = {}\n",
    "for id, val in danno.items():\n",
    "    for v in val:\n",
    "        vects[id] = vects.get(id, []) + [mix_text_vec2vec(val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from net.train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dense net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 23300\n",
    "\n",
    "X, y = [], []\n",
    "for id, data in imgs.items():\n",
    "    while id[0] == '0':\n",
    "        id = id[1:]\n",
    "    try:\n",
    "        for vec in vects[id]:\n",
    "            X.append(vec)\n",
    "            y.append(data[1])\n",
    "    except Exception as ex: \n",
    "        print(ex)\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "X_train, y_train, X_val, y_val = X[:train_size], y[:train_size], X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import theano.tensor as T\n",
    "import theanonet = build_dense_net('save_01-11-2017_21-45-26.net')\n",
    "training_dn = Training(net, 40)\n",
    "training_dn.set_Xy(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training_dn.training(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_net(net['last'], 'save_{}.net'.format('LAST'+get_cur_time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2vec(text, w2v):\n",
    "    vecs = [w2v[word] for word in sent2words(text) if word in w2v]\n",
    "    return mix_text_vec2vec(vecs)\n",
    "\n",
    "text2vec('dog run').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img(dataDir, file_name):\n",
    "    img = imageio.imread(dataDir + '/' + file_name)\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    img = img.resize((200,200), PIL.Image.ANTIALIAS)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def show_img_by_id(img_id):\n",
    "    show_img(dataDir + '/img', img_id + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_imgs_by_vec(vec, imgs=imgs, net=net):\n",
    "    result = [(id, np.linalg.norm(vec - point[1])) for id, point in imgs.items()]\n",
    "    return result\n",
    "\n",
    "def show_t2i(text, count=3, net=net):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    good_imgs = get_imgs_by_vec(vec)[:count]\n",
    "    good_imgs.sort(key=lambda x: x[1])\n",
    "    display(good_imgs)\n",
    "    for id, _ in good_imgs:\n",
    "        print(id)\n",
    "        show_img_by_id(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('a person attempting a jump with a skateboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "procesed_captions = []\n",
    "for i, text in enumerate(captions):\n",
    "    mod = 100\n",
    "    procesed_captions.append(net.predict_fun_det([text2vec(text)])[0])\n",
    "    if i % mod == 0:\n",
    "        print('Processed {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_texts_by_vec(vec, texts=captions, procesed_texts=procesed_captions):\n",
    "    result = []\n",
    "    for text, point in zip(texts, procesed_texts):\n",
    "        dis = np.linalg.norm(vec - point)\n",
    "        result.append((text, dis))\n",
    "    result.sort(key=lambda x: x[1])\n",
    "    return result\n",
    "\n",
    "def show_i2t(img_id, count=3):\n",
    "    show_img_by_id(img_id)\n",
    "    vec = imgs[img_id][1]\n",
    "    good_text = get_texts_by_vec(vec)[:count]\n",
    "    print(*good_text, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_i2t('000000565597', count=4)\n",
    "show_i2t('000000564280', count=4)\n",
    "show_i2t('000000554291', count=4)\n",
    "show_i2t('000000543043', count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_texts_by_text(text, net=net, texts=captions, procesed_texts=procesed_captions):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    result = []\n",
    "    for text, point in zip(texts, procesed_texts):\n",
    "        dis = np.linalg.norm(vec - point)\n",
    "        result.append((text, dis))\n",
    "    result.sort(key=lambda x: x[1])\n",
    "    return result\n",
    "\n",
    "def show_t2t(text, count=3):\n",
    "    print(text)\n",
    "    good_text = get_texts_by_text(text)[:count]\n",
    "    print(*good_text, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_t2t('A big dog is running')\n",
    "show_t2t('Green apple')\n",
    "show_t2t('donut on the table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('A purple and white bus in a parking lot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('donut on table', count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('cat under door', count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('apples on tree', count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('baby with mother', count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_t2i('man with an orange', count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_text_img(text, img_id):\n",
    "    vec_1 = net.predict_fun_det([text2vec(text)])[0]\n",
    "    vec_2 = imgs[img_id][1]\n",
    "    return np.linalg.norm(vec_1 - vec_2)\n",
    "\n",
    "display(distance_text_img('man with orange', '000000138115'))\n",
    "display(distance_text_img('man with orange', '000000234526'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import process\n",
    "\n",
    "def frames_load(dir_name):\n",
    "    frames = {}\n",
    "    for file_name in os.listdir(dir_name + '/video_data'):\n",
    "        if '.' in file_name and file_name.split('.')[1] == 'data':\n",
    "            with open('{}/video_data/{}'.format(dir_name, file_name), 'rb') as fl:\n",
    "                data = pickle.load(fl)\n",
    "                frames.update(data)\n",
    "    return frames\n",
    "\n",
    "frames = frames_load(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_v = {k: v['fc7'] for k, v in frames.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_name = 'Africa.mp4'\n",
    "vd = imageio.get_reader(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_video_by_moment(moment, vd=vd):\n",
    "    img = vd.get_data(moment)\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    img = img.resize((200,200), PIL.Image.ANTIALIAS)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_video_t2i(text, count=3, net=net):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    good_imgs = get_imgs_by_vec(vec, imgs=imgs_v)[:count]\n",
    "    good_imgs.sort(key=lambda x: x[1])\n",
    "    display(good_imgs)\n",
    "    for id, _ in good_imgs:\n",
    "        print(id)\n",
    "        show_video_by_moment(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.interpolate as interpolate\n",
    "\n",
    "def show_video_t2graph(text, net=net):\n",
    "    vec = net.predict_fun_det([text2vec(text)])[0]\n",
    "    good_imgs = get_imgs_by_vec(vec, imgs=imgs_v)\n",
    "    good_imgs.sort(key=lambda x: x[0])\n",
    "    x, y = np.transpose(good_imgs)\n",
    "    print(y[:6])\n",
    "    print(len(y))\n",
    "    k = 1\n",
    "    x = x[:k + 1] + x\n",
    "    y = interpolate.BSpline(2.5, x, y, k)\n",
    "    plt.plot(y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_video_t2graph('tiger in forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_video_t2i('tiger in forest', count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterization img and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.manifold as manifold\n",
    "import sklearn.decomposition as decomposition\n",
    "import \n",
    "\n",
    "def show_manifold(mani, imgs, vects, n=200, net=net):\n",
    "    list_imgs = list(imgs.items())\n",
    "    perm = np.arange(len(list_imgs))\n",
    "    np.random.shuffle(perm)\n",
    "    points = []\n",
    "    colors = []\n",
    "    for i in perm[:n]:\n",
    "        if np.random.randint(0, 2) == 0:\n",
    "            colors.append(1)\n",
    "            points.append(list_imgs[i][1][1])\n",
    "        else:\n",
    "            colors.append(0)\n",
    "            id = list_imgs[i][0]\n",
    "            while id[0] == '0':\n",
    "                id = id[1:]\n",
    "            vec = net.predict_fun_det([vects[id][1]])[0]\n",
    "            points.append(vec)\n",
    "    \n",
    "    c_vec = mani.fit_transform(points)\n",
    "    plt.scatter(*(c_vec).T, c=colors, alpha=0.5, s=50, linewidths=0)\n",
    "    plt.show()\n",
    "    \n",
    "show_manifold(manifold.TSNE(), imgs, vects)\n",
    "show_manifold(decomposition.PCA(n_components=2), imgs, vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lasagne\n",
    "lasagne.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
